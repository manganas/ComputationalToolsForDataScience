{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e666416",
   "metadata": {},
   "source": [
    "## Content based recommendation system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588f79c2",
   "metadata": {},
   "source": [
    "In this notebook, the text content of the movies from the `merged` dataset is going to be alalyzed. The goal is to rank all the movies in the dataset based on a similarity measure with the input movie. For similarity measures, the cosine similarity will be used. Moreover, the content comes from the movies plots and possibly also the keywords. In order to remove the most common words, TF-IDF is used. Finally, the input to the TF-IDF algorithm will be the lemmatized text from each movie's content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42f313e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common libraries imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcfa3752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /home/user/.local/lib/python3.7/site-packages (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/user/.local/lib/python3.7/site-packages (from nltk) (2022.9.13)\n",
      "Requirement already satisfied: click in /home/user/.local/lib/python3.7/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in /home/user/.local/lib/python3.7/site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: tqdm in /home/user/.local/lib/python3.7/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: importlib-metadata in /home/user/.local/lib/python3.7/site-packages (from click->nltk) (4.10.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/user/.local/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (3.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in /home/user/.local/lib/python3.7/site-packages (from importlib-metadata->click->nltk) (4.0.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/user/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/user/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not as common libraries imports and installation. \n",
    "!python3 -m pip install nltk ## For linux and not environment\n",
    "# !pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26758cf7",
   "metadata": {},
   "source": [
    "Read the `merged` dataset, or its 'cleaned' version, that has duplicates removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cf4027d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = data.sort_values('Release Year', ascending=False).drop_duplicates(subset=['Title', 'Release Year'], keep='last')\n",
    "# a.loc[a.Title=='The Mask']['release_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ade68f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Data/data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab59590e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info(index):\n",
    "    '''\n",
    "    Helper function used for an initial overview of the dataset\n",
    "    '''\n",
    "    print(f\"Title:\\n{data.iloc[index]['Title']}\\n\")\n",
    "    print(f\"Release Year:\\n{data.iloc[index]['Release Year']}\\n\")\n",
    "    print(f\"Link:\\n{data.iloc[index]['Wiki Page']}\\n\")\n",
    "    print(f\"Tagline:\\n{data.iloc[index]['tagline']}\\n\")\n",
    "    print(f\"Overview:\\n{data.iloc[index]['overview']}\\n\")\n",
    "    print(f\"Summary:\\n{data.iloc[index]['Plot']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7cee69",
   "metadata": {},
   "source": [
    "As an example, use `print_info` for a random movie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "723fc500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:\n",
      "Me and the Colonel\n",
      "\n",
      "Release Year:\n",
      "1958\n",
      "\n",
      "Link:\n",
      "https://en.wikipedia.org/wiki/Me_and_the_Colonel\n",
      "\n",
      "Tagline:\n",
      "nan\n",
      "\n",
      "Overview:\n",
      "Jacobowsky, a Jewish refugee, flees from the Nazis with an aristocratic, anti-semitic Polish officer trying to get papers to England. Jurgens learns to appreciate Jacobowsky, despite their competition for the same woman, and together they outwit their pursuers\n",
      "\n",
      "Summary:\n",
      "In Paris during the World War II invasion of France by Nazi Germany, Jewish refugee S. L. Jacobowsky (Danny Kaye) seeks to leave the country before it falls. Meanwhile, Polish diplomat Dr. Szicki (Ludwig Stössel) gives antisemitic, autocratic Polish Colonel Prokoszny (Curt Jürgens) secret information that must be delivered to London by a certain date.\r\n",
      "The resourceful Jacobowsky, who has had to flee from the Nazis several times previously, manages to \"buy\" an automobile from the absent Baron Rothschild's chauffeur. Prokoszny peremptorily requisitions the car, but finds he must accept an unwelcome passenger when he discovers that Jacobowsky has had the foresight to secure gasoline. The ill-matched pair (coincidentally from the same village in Poland) and the colonel's orderly, Szabuniewicz (Akim Tamiroff), drive away.\r\n",
      "Jacobowsky is dismayed when the colonel first heads to Reims in the direction of the advancing German army to pick up his girlfriend, Suzanne Roualet (Nicole Maurey), a French innkeeper's daughter. Prior to their arrival, Suzanne attracts the unwanted admiration of German Major Von Bergen (Alexander Scourby), but he is called away before he can become better acquainted with her.\r\n",
      "As they flee south, Jacobowsky begins to fall in love with Suzanne. At one stop, Jacobowsky manages to find the group magnificent lodgings at a chateau by telling its proud royalist owner that unoccupied France is to become a monarchy headed by the colonel. A drunk Prokoszny challenges Jacobowsky to a duel, but Jacobowsky manages to defuse the situation. When the Germans, under Von Bergen, occupy the chateau, the foursome barely get away.\r\n",
      "They are chased by Von Bergen, but the assistance of a sympathetic Mother Superior (Martita Hunt) enables them to shake off their pursuers and reach a prearranged rendezvous with a British submarine. There, however, the submarine's commander informs them that there is only room for two. Suzanne makes the colonel and Jacobowsky go, while she remains behind to fight the invaders in her own way.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_info(12456)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413cec1f",
   "metadata": {},
   "source": [
    "Which text should we use as content? We can use `tagline` as an alternative title, `overview` which is a sentence that summarizes the movie and `Plot`, the summary of the movie. The latter is in general a longer text. We can use either the latter or for each movie create a txt document that contains the desired text.  \n",
    "\n",
    "In the following, as a prototype, I am only using the `Plot`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93bf337",
   "metadata": {},
   "source": [
    "There are 2 ways to normalize text:Stemming and Lemmatization. The difference can be found [here](https://www.guru99.com/stemming-lemmatization-python-nltk.html). In the following I am using Lemmatization.  \n",
    "\n",
    "The procedure is as follows. Lemmatize each movie's text content, get the frequency for each movie's lemmas and then use TF-IDF. To this end, I create a dataframe to store, the movie title, the relase year and the lemmas as list of words for each movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b19b865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8aaab3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+') # Remove punctuation\n",
    "wordnet_lemmatizer = WordNetLemmatizer() # Create lemmatizer\n",
    "\n",
    "# text = \"studies studying cries cry\"\n",
    "# tokenization = nltk.word_tokenize(text)\n",
    "# for w in tokenization:\n",
    "#     print(\"Lemma for {} is {}\".format(w, wordnet_lemmatizer.lemmatize(w)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2ad947de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lemmas_list(content_txt):\n",
    "    lemmas = []    \n",
    "    tokenization = tokenizer.tokenize(content_txt.lower()) # Lowercase the whole text, to avoid dealing with case\n",
    "    for w in tokenization:\n",
    "        # Do not consider single characters. Can be resolved via tf-idf,\n",
    "        # but maybe there are single characters due to wrong line breaks.\n",
    "        if len(w)<2:\n",
    "            continue\n",
    "        lemmas.append(wordnet_lemmatizer.lemmatize(w))\n",
    "    \n",
    "    # Since the text is lowercase, we can also return only the unique tokens\n",
    "    return set(lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dff73f2",
   "metadata": {},
   "source": [
    "Test this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "34023b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gain\n",
      "grudgingly\n",
      "revenge\n",
      "becomes\n",
      "occultist\n",
      "favor\n",
      "finger\n",
      "beginning\n",
      "fall\n",
      "road\n",
      "grueling\n",
      "guardian\n",
      "soldier\n",
      "rent\n",
      "agrees\n",
      "kitchen\n",
      "dark\n",
      "go\n",
      "punishing\n",
      "special\n",
      "about\n",
      "cut\n",
      "her\n",
      "on\n",
      "they\n",
      "spell\n",
      "fail\n",
      "instruction\n",
      "beatific\n",
      "drive\n",
      "serious\n",
      "his\n",
      "life\n",
      "seven\n",
      "down\n",
      "hearing\n",
      "have\n",
      "quiet\n",
      "kidnapped\n",
      "some\n",
      "explains\n",
      "grant\n",
      "both\n",
      "joseph\n",
      "ha\n",
      "allowed\n",
      "able\n",
      "summon\n",
      "brilliant\n",
      "ceremony\n",
      "discloses\n",
      "out\n",
      "another\n",
      "disturbed\n",
      "culminated\n",
      "month\n",
      "honest\n",
      "seeing\n",
      "awakens\n",
      "he\n",
      "angel\n",
      "head\n",
      "cpr\n",
      "perimeter\n",
      "order\n",
      "including\n",
      "crossed\n",
      "asks\n",
      "everything\n",
      "solomon\n",
      "peril\n",
      "grave\n",
      "insist\n",
      "dishonesty\n",
      "is\n",
      "convince\n",
      "complains\n",
      "armor\n",
      "a\n",
      "because\n",
      "unreadable\n",
      "knife\n",
      "rural\n",
      "side\n",
      "something\n",
      "isolated\n",
      "people\n",
      "tormenting\n",
      "impaling\n",
      "sorry\n",
      "their\n",
      "begin\n",
      "presence\n",
      "infected\n",
      "year\n",
      "but\n",
      "this\n",
      "smile\n",
      "after\n",
      "the\n",
      "wound\n",
      "get\n",
      "accuses\n",
      "smash\n",
      "one\n",
      "complies\n",
      "old\n",
      "howl\n",
      "sophia\n",
      "tell\n",
      "over\n",
      "by\n",
      "burial\n",
      "increasingly\n",
      "lengthy\n",
      "afterward\n",
      "fine\n",
      "too\n",
      "kind\n",
      "retreat\n",
      "work\n",
      "car\n",
      "ritual\n",
      "medical\n",
      "unpure\n",
      "meager\n",
      "from\n",
      "bitter\n",
      "rite\n",
      "empty\n",
      "forgive\n",
      "do\n",
      "then\n",
      "sign\n",
      "won\n",
      "eventually\n",
      "grieving\n",
      "spend\n",
      "start\n",
      "basement\n",
      "light\n",
      "whoever\n",
      "fill\n",
      "awaiting\n",
      "house\n",
      "lead\n",
      "tempered\n",
      "must\n",
      "demon\n",
      "water\n",
      "re\n",
      "be\n",
      "frustrated\n",
      "find\n",
      "wale\n",
      "of\n",
      "dozen\n",
      "been\n",
      "night\n",
      "for\n",
      "that\n",
      "being\n",
      "them\n",
      "point\n",
      "impairing\n",
      "step\n",
      "taking\n",
      "invisible\n",
      "not\n",
      "white\n",
      "sleep\n",
      "enters\n",
      "further\n",
      "leave\n",
      "killed\n",
      "she\n",
      "refuse\n",
      "push\n",
      "which\n",
      "dy\n",
      "arrived\n",
      "distance\n",
      "dealing\n",
      "power\n",
      "accidentally\n",
      "large\n",
      "beyond\n",
      "dead\n",
      "off\n",
      "massive\n",
      "angry\n",
      "back\n",
      "forgiveness\n",
      "will\n",
      "long\n",
      "birthing\n",
      "demanding\n",
      "revives\n",
      "various\n",
      "pond\n",
      "exercise\n",
      "voice\n",
      "once\n",
      "required\n",
      "drag\n",
      "nearby\n",
      "know\n",
      "made\n",
      "performs\n",
      "admits\n",
      "insisting\n",
      "walking\n",
      "how\n",
      "an\n",
      "at\n",
      "if\n",
      "drowns\n",
      "just\n",
      "help\n",
      "when\n",
      "harrowing\n",
      "in\n",
      "to\n",
      "rest\n",
      "real\n",
      "tub\n",
      "speak\n",
      "however\n",
      "discover\n",
      "later\n",
      "visibly\n",
      "him\n",
      "and\n",
      "treat\n",
      "mansion\n",
      "short\n",
      "realize\n",
      "with\n",
      "son\n",
      "appearing\n",
      "say\n",
      "pleading\n",
      "it\n",
      "painful\n",
      "upon\n",
      "supply\n",
      "away\n",
      "menacing\n",
      "book\n",
      "before\n",
      "methodically\n",
      "ask\n"
     ]
    }
   ],
   "source": [
    "txt = data.iloc[459].Plot\n",
    "a = create_lemmas_list(txt)\n",
    "for el in a:\n",
    "    print(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dba963c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb117ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
