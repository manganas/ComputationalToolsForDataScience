{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e666416",
   "metadata": {},
   "source": [
    "## Content based recommendation system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b7c01e",
   "metadata": {},
   "source": [
    "Content based recommender systems do not make use of data from other users to recommend a movie. Instead, they utilize a descriptive set of attributes such as keywords or the summary of a movie. The disadvantage is that these systems will recommend the same movie to the user, based on the input. However, they could be useful in recommending a movie that not many people have seen or rated.  \n",
    "\n",
    "In the content based recommendation system it is only the user that plays a role in the recommendation. This method can also be combined with collaborative filtering methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588f79c2",
   "metadata": {},
   "source": [
    "In this notebook, the text content of the movies from the `merged` dataset is going to be alalyzed. The goal is to rank all the movies in the dataset based on a similarity measure with the input movie. For similarity measures, the cosine similarity will be used. Moreover, the content comes from the movies plots and possibly also the keywords. In order to remove the most common words, TF-IDF is used. Finally, the input to the TF-IDF algorithm will be the lemmatized text from each movie's content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42f313e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common libraries imports\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bcfa3752",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not as common libraries imports and installation. \n",
    "# !python3 -m pip install nltk ## For linux and not environment\n",
    "# !pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0efc584",
   "metadata": {},
   "source": [
    "Since it is a good idea to remove stop words from tf idf calculations, as stated also in [Chapter 1.3.1 MMDS](http://mmds.org/), a list of English stop words is created:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "324eefda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26758cf7",
   "metadata": {},
   "source": [
    "Read the `merged` dataset, or its 'cleaned' version, that has duplicates removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4cf4027d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = data.sort_values('Release Year', ascending=False).drop_duplicates(subset=['Title', 'Release Year'], keep='last')\n",
    "# a.loc[a.Title=='The Mask']['release_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ade68f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Data/data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab59590e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_info(index):\n",
    "    '''\n",
    "    Helper function used for an initial overview of the dataset\n",
    "    '''\n",
    "    print(f\"Title:\\n{data.iloc[index]['Title']}\\n\")\n",
    "    print(f\"Release Year:\\n{data.iloc[index]['Release Year']}\\n\")\n",
    "    print(f\"Link:\\n{data.iloc[index]['Wiki Page']}\\n\")\n",
    "    print(f\"Tagline:\\n{data.iloc[index]['tagline']}\\n\")\n",
    "    print(f\"Overview:\\n{data.iloc[index]['overview']}\\n\")\n",
    "    print(f\"Summary:\\n{data.iloc[index]['Plot']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7cee69",
   "metadata": {},
   "source": [
    "As an example, use `print_info` for a random movie:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "723fc500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title:\n",
      "Me and the Colonel\n",
      "\n",
      "Release Year:\n",
      "1958\n",
      "\n",
      "Link:\n",
      "https://en.wikipedia.org/wiki/Me_and_the_Colonel\n",
      "\n",
      "Tagline:\n",
      "nan\n",
      "\n",
      "Overview:\n",
      "Jacobowsky, a Jewish refugee, flees from the Nazis with an aristocratic, anti-semitic Polish officer trying to get papers to England. Jurgens learns to appreciate Jacobowsky, despite their competition for the same woman, and together they outwit their pursuers\n",
      "\n",
      "Summary:\n",
      "In Paris during the World War II invasion of France by Nazi Germany, Jewish refugee S. L. Jacobowsky (Danny Kaye) seeks to leave the country before it falls. Meanwhile, Polish diplomat Dr. Szicki (Ludwig Stössel) gives antisemitic, autocratic Polish Colonel Prokoszny (Curt Jürgens) secret information that must be delivered to London by a certain date.\r\n",
      "The resourceful Jacobowsky, who has had to flee from the Nazis several times previously, manages to \"buy\" an automobile from the absent Baron Rothschild's chauffeur. Prokoszny peremptorily requisitions the car, but finds he must accept an unwelcome passenger when he discovers that Jacobowsky has had the foresight to secure gasoline. The ill-matched pair (coincidentally from the same village in Poland) and the colonel's orderly, Szabuniewicz (Akim Tamiroff), drive away.\r\n",
      "Jacobowsky is dismayed when the colonel first heads to Reims in the direction of the advancing German army to pick up his girlfriend, Suzanne Roualet (Nicole Maurey), a French innkeeper's daughter. Prior to their arrival, Suzanne attracts the unwanted admiration of German Major Von Bergen (Alexander Scourby), but he is called away before he can become better acquainted with her.\r\n",
      "As they flee south, Jacobowsky begins to fall in love with Suzanne. At one stop, Jacobowsky manages to find the group magnificent lodgings at a chateau by telling its proud royalist owner that unoccupied France is to become a monarchy headed by the colonel. A drunk Prokoszny challenges Jacobowsky to a duel, but Jacobowsky manages to defuse the situation. When the Germans, under Von Bergen, occupy the chateau, the foursome barely get away.\r\n",
      "They are chased by Von Bergen, but the assistance of a sympathetic Mother Superior (Martita Hunt) enables them to shake off their pursuers and reach a prearranged rendezvous with a British submarine. There, however, the submarine's commander informs them that there is only room for two. Suzanne makes the colonel and Jacobowsky go, while she remains behind to fight the invaders in her own way.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_info(12456)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413cec1f",
   "metadata": {},
   "source": [
    "Which text should we use as content? We can use `tagline` as an alternative title, `overview` which is a sentence that summarizes the movie and `Plot`, the summary of the movie. The latter is in general a longer text. We can use either the latter or for each movie create a txt document that contains the desired text.  \n",
    "\n",
    "In the following, as a prototype, I am only using the `Plot`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93bf337",
   "metadata": {},
   "source": [
    "There are 2 ways to normalize text:Stemming and Lemmatization. The difference can be found [here](https://www.guru99.com/stemming-lemmatization-python-nltk.html). In the following I am using Lemmatization.  \n",
    "\n",
    "The procedure is as follows. Lemmatize each movie's text content, get the frequency for each movie's lemmas and then use TF-IDF. To this end, I create a dataframe to store, the movie title, the relase year and the lemmas as list of words for each movie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b19b865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import RegexpTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8aaab3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+') # Remove punctuation\n",
    "wordnet_lemmatizer = WordNetLemmatizer() # Create lemmatizer\n",
    "\n",
    "# text = \"studies studying cries cry\"\n",
    "# tokenization = nltk.word_tokenize(text)\n",
    "# for w in tokenization:\n",
    "#     print(\"Lemma for {} is {}\".format(w, wordnet_lemmatizer.lemmatize(w)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ad947de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lemmas_list(content_txt):\n",
    "    lemmas = []    \n",
    "    tokenization = tokenizer.tokenize(content_txt.lower()) # Lowercase the whole text, to avoid dealing with case\n",
    "    for w in tokenization:\n",
    "        # Do not consider single characters. Can be resolved via tf-idf,\n",
    "        # but maybe there are single characters due to wrong line breaks.\n",
    "        if w in stop_words:\n",
    "            continue\n",
    "        lemmas.append(wordnet_lemmatizer.lemmatize(w, wordnet.VERB))\n",
    "    \n",
    "    return lemmas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dff73f2",
   "metadata": {},
   "source": [
    "Test this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34023b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt = data.iloc[459].Plot\n",
    "a = create_lemmas_list(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb416007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.1', 'Unnamed: 0', 'adult', 'belongs_to_collection',\n",
       "       'budget', 'genres', 'homepage', 'id', 'imdb_id', 'original_language',\n",
       "       'original_title', 'overview', 'popularity', 'poster_path',\n",
       "       'production_companies', 'production_countries', 'release_date',\n",
       "       'revenue', 'runtime', 'spoken_languages', 'status', 'tagline', 'title',\n",
       "       'video', 'vote_average', 'vote_count', 'Release Year', 'Title',\n",
       "       'Origin/Ethnicity', 'Director', 'Cast', 'Genre', 'Wiki Page', 'Plot'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f5d8101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df to hold the movies and the tokenized text\n",
    "movie_plots_tokens_df = data[['Title', \"Plot\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3116514",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokenization = tokenizer.tokenize(text.lower())\n",
    "    tokens = [ wordnet_lemmatizer.lemmatize(token, wordnet.VERB) for token in tokenization if token not in stop_words and token.isalpha() ]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0818c906",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp2\\ipykernel_9880\\863147497.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  movie_plots_tokens_df['Tokens'] = movie_plots_tokens_df['Plot'].apply(tokenize)\n"
     ]
    }
   ],
   "source": [
    "movie_plots_tokens_df['Tokens'] = movie_plots_tokens_df['Plot'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "961f2c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [four, friends, jess, scarlett, johansson, ali...\n",
       "1        [bhairava, kala, bhairava, telugu, version, vi...\n",
       "2        [present, day, paris, diana, receive, photogra...\n",
       "3        [du, qiu, chinese, lawyer, defeat, many, legal...\n",
       "4        [feral, puppy, name, toby, whisk, away, dog, p...\n",
       "                               ...                        \n",
       "16224    [rarebit, fiend, gorge, welsh, rarebit, restau...\n",
       "16225    [scenes, introduce, use, line, poem, santa, cl...\n",
       "16226    [film, open, two, bandits, break, railroad, te...\n",
       "16227    [alice, follow, large, white, rabbit, rabbit, ...\n",
       "16228    [earliest, know, adaptation, classic, fairytal...\n",
       "Name: Tokens, Length: 16229, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_plots_tokens_df.Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4b7968f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac16375",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af23c5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d2781e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a1dd66cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e3b0723",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer().fit_transform(data.Plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e5ebfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfov = TfidfVectorizer().fit_transform(data.overview.dropna())\n",
    "tftit = TfidfVectorizer().fit_transform(data.Title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fea4909e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16229, 96675)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a105952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 74013)\t0.034568082220997325\n",
      "  (0, 81454)\t0.033435595582795144\n",
      "  (0, 74364)\t0.013308550019604754\n",
      "  (0, 56348)\t0.027812437746473205\n",
      "  (0, 85863)\t0.010609621262672965\n",
      "  (0, 23956)\t0.012365860880066592\n",
      "  (0, 62884)\t0.03167092009260365\n",
      "  (0, 63510)\t0.08195537174637643\n",
      "  (0, 66547)\t0.029613003944778026\n",
      "  (0, 26362)\t0.023030368265445144\n",
      "  (0, 79961)\t0.017174055255996797\n",
      "  (0, 50625)\t0.0178905632788683\n",
      "  (0, 4689)\t0.01605887389499494\n",
      "  (0, 27796)\t0.01699276967933318\n",
      "  (0, 59685)\t0.010781347398769838\n",
      "  (0, 25522)\t0.016948493465067747\n",
      "  (0, 19796)\t0.020830729689209574\n",
      "  (0, 66410)\t0.020413866647601107\n",
      "  (0, 70779)\t0.04823092433632978\n",
      "  (0, 57092)\t0.011195283635910717\n",
      "  (0, 52141)\t0.011381525510227022\n",
      "  (0, 38311)\t0.022827290520951254\n",
      "  (0, 34305)\t0.013993858233721575\n",
      "  (0, 71337)\t0.02292776048399439\n",
      "  (0, 93267)\t0.012912602503844883\n",
      "  :\t:\n",
      "  (16228, 90218)\t0.02484857428075115\n",
      "  (16228, 53856)\t0.056155437364953466\n",
      "  (16228, 25207)\t0.06988218907834902\n",
      "  (16228, 13689)\t0.032924271705393984\n",
      "  (16228, 93474)\t0.03898846535620248\n",
      "  (16228, 8549)\t0.030636927452897804\n",
      "  (16228, 85808)\t0.026534851705332745\n",
      "  (16228, 38890)\t0.061572977824010534\n",
      "  (16228, 39034)\t0.036115595152979386\n",
      "  (16228, 37883)\t0.11232240076581142\n",
      "  (16228, 93516)\t0.04403948824847302\n",
      "  (16228, 85818)\t0.02835999872327086\n",
      "  (16228, 37565)\t0.021406849658275988\n",
      "  (16228, 93679)\t0.03948636337251892\n",
      "  (16228, 86003)\t0.06300753178531032\n",
      "  (16228, 13177)\t0.019200885873019404\n",
      "  (16228, 85774)\t0.2298036392139879\n",
      "  (16228, 85753)\t0.019204489812044107\n",
      "  (16228, 33946)\t0.03416680160659864\n",
      "  (16228, 86701)\t0.06629242129041227\n",
      "  (16228, 42932)\t0.06871493420798531\n",
      "  (16228, 5609)\t0.059270550004258064\n",
      "  (16228, 61003)\t0.05070362412000487\n",
      "  (16228, 4064)\t0.0497990502097035\n",
      "  (16228, 41365)\t0.03396961195690101\n"
     ]
    }
   ],
   "source": [
    "print(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d91c65d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.034568082220997325"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf[0,74013]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92051730",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = linear_kernel(tf, tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d70970e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_simtit = linear_kernel(tftit, tftit)\n",
    "cosine_simov = linear_kernel(tfov, tfov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3a869ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2  = data['overview'].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf74f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b28e2da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title, df, sim_measure ):\n",
    "    df = df.copy()\n",
    "    smd = df.reset_index()\n",
    "    titles = df['Title']\n",
    "    indices = pd.Series(smd.index, index=smd['Title'])\n",
    "    idx = indices[title]\n",
    "    sim_scores = list(enumerate(sim_measure[idx]))\n",
    "    print(sim_scores)\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:31]\n",
    "    movie_indices = [i[0] for i in sim_scores]\n",
    "    return titles.iloc[movie_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "75d7eaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "title='Batman'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a645240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, array([0.13604804, 0.06318244, 0.11339312, ..., 0.12763941, 0.11021525,\n",
      "       0.10336239])), (1, array([0.15187321, 0.07219298, 0.13165538, ..., 0.14485844, 0.11529897,\n",
      "       0.09693904])), (2, array([0.11484572, 0.05908738, 0.10156317, ..., 0.12178146, 0.09699992,\n",
      "       0.07861162]))]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp2\\ipykernel_9880\\2184547717.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrecom_plot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_recommendations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcosine_sim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mrecom_over\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_recommendations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcosine_simov\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mrecom_title\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_recommendations\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcosine_simtit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp2\\ipykernel_9880\\2724399856.py\u001b[0m in \u001b[0;36mget_recommendations\u001b[1;34m(title, df, sim_measure)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0msim_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim_measure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim_scores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0msim_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msim_scores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0msim_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msim_scores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m31\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mmovie_indices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msim_scores\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "recom_plot = get_recommendations(title, data,cosine_sim)\n",
    "recom_over = get_recommendations(title, data,cosine_simov)\n",
    "recom_title = get_recommendations(title, data,cosine_simtit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9cab53a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'recom_plot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp2\\ipykernel_9880\\4135106375.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecom_plot\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'recom_plot' is not defined"
     ]
    }
   ],
   "source": [
    "type(recom_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a62add9",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations_df = pd.concat([ recom_over.reset_index(drop=True), recom_title.reset_index(drop=True), recom_plot.reset_index(drop=True) ], axis=1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0d079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendations_df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dba963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tf(document):\n",
    "#     doc_tokens = create_lemmas_list(document)\n",
    "#     freq_dist = nltk.FreqDist(doc_tokens)\n",
    "    \n",
    "#     # FreqDist return the dictionary sorted in descending order.\n",
    "#     # I did not find this explicitly in the docs, so I find the max freq in the document\n",
    "#     max_freq = sorted( list(freq_dist.values()), reverse=True )[0]\n",
    "    \n",
    "#     tfs = {token:freq/max_freq for (token, freq) in freq_dist.items() }\n",
    "#     return tfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb117ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "# def df(data_frame):\n",
    "#     df_dict = {}\n",
    "#     for i in tqdm(range(len(data_frame))):\n",
    "#         for token in set(data_frame.iloc[i].Tokens):\n",
    "#             for j in range(len(data_frame)):\n",
    "#                 document = set(data_frame.iloc[j].Tokens)\n",
    "#                 if token in document:\n",
    "#                     df_dict[token] = df_dict.get(token,[j]) + [j]\n",
    "#     return df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2351f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df(movie_plots_tokens_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8b6bb8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
